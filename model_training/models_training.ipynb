{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, cv2, glob, json, base64\n",
    "\n",
    "# from PIL import Image\n",
    "from blend_modes import normal\n",
    "\n",
    "\n",
    "# Lets make sure working directory is project root\n",
    "if os.getcwd().rsplit(os.path.sep,1)[1]==\"model_training\":\n",
    "    os.chdir( os.getcwd().rsplit(os.path.sep,1)[0] )\n",
    "\n",
    "# Load up our lookup_table used for labels\n",
    "with open(os.path.join(\"public\",\"lookup_table.json\")) as json_file:\n",
    "    lookup_table  = json.load(json_file)\n",
    "\n",
    "# Define functions used throughout the document\n",
    "def read_png(path):\n",
    "    image = cv2.imread(path,-1)\n",
    "    return cv2.cvtColor(image,cv2.COLOR_BGR2BGRA) if len(image.shape) > 2 and image.shape[2] == 3 else image\n",
    "\n",
    "def read_jpeg(path):\n",
    "    BGR = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    BGRA = cv2.cvtColor(BGR,cv2.COLOR_BGR2BGRA)\n",
    "    BGRA[:,:,3] = 255\n",
    "    return BGRA\n",
    "    \n",
    "def layer( image_a, image_b ):\n",
    "    return normal(image_a.astype(float), image_b.astype(float), 1.).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_champion_and_skin_training_images( champion_image_path ):\n",
    "    \n",
    "    # 1.A loading and preparing assets\n",
    "    champion = cv2.copyMakeBorder(read_jpeg(champion_image_path), 0, 5, 5, 0, cv2.BORDER_CONSTANT,value=(0,0,0,255))\n",
    "    shard_border = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"shard.png\")), (385,385))\n",
    "    permanent_border = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"permanent.png\")), (385,385))\n",
    "    token_6_border = read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"champion_token_6.png\"))[5:74, :]\n",
    "    token_6_border = cv2.resize(token_6_border, (385,385))\n",
    "    token_7_border = read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"champion_token_7.png\"))[5:74, :]\n",
    "    token_7_border = cv2.resize(token_7_border, (385,385))\n",
    "    quantity_background = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"quantity_background.png\")), (385,385))\n",
    "\n",
    "    champion_id = champion_image_path.rsplit(os.path.sep,1)[1].split('.')[0]\n",
    "    price = lookup_table[champion_id][1]\n",
    "\n",
    "    if lookup_table[champion_id][2] == 1: legacy_icon = read_png(os.path.join(\"model_training\",\"assets\",\"tag_icons\",\"legacy.png\"))\n",
    "        \n",
    "    if price == \"special\": rarity_icon = read_png(os.path.join(\"model_training\",\"assets\",\"rarity_icons\",\"rarity_mythic.png\"))\n",
    "    if price == 3250: rarity_icon = read_png(os.path.join(\"model_training\",\"assets\",\"rarity_icons\",\"rarity_ultimate.png\"))\n",
    "    if price == 1820: rarity_icon = read_png(os.path.join(\"model_training\",\"assets\",\"rarity_icons\",\"rarity_legendary.png\"))\n",
    "    if price == 1350: rarity_icon = read_png(os.path.join(\"model_training\",\"assets\",\"rarity_icons\",\"rarity_epic.png\"))\n",
    "\n",
    "    # 1.B Resize rarity and legacy icons to 395x395 pixel resolution overlay images\n",
    "    if 'legacy_icon' in locals():\n",
    "        legacy_icon = cv2.resize(legacy_icon, (110,110))\n",
    "        legacy_icon = cv2.copyMakeBorder(legacy_icon, 291, 0, 0, 297, cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "        legacy_icon = legacy_icon[0:395,legacy_icon.shape[1]-395:legacy_icon.shape[1]]\n",
    "\n",
    "    if 'rarity_icon' in locals():\n",
    "        rarity_icon = cv2.resize(rarity_icon, (385,int(385/rarity_icon.shape[1]*rarity_icon.shape[0])))\n",
    "        rarity_icon = cv2.copyMakeBorder(rarity_icon, 285, 5, 5, 5, cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "        rarity_icon = rarity_icon[0:395,0:395]\n",
    "\n",
    "    # 2. Set up borders this asset uses in the loot tab\n",
    "    if champion_id.endswith(\"000\"):\n",
    "        borders = (shard_border, permanent_border, token_6_border, token_7_border)\n",
    "    else:\n",
    "        borders = (shard_border, permanent_border)\n",
    "    \n",
    "    # 3. Create variations of assets from layers\n",
    "    for border_index in range(len(borders)):\n",
    "        for shadow in (False, True):\n",
    "            image = layer(champion, quantity_background) if shadow else champion\n",
    "            image = layer(image, borders[border_index])\n",
    "            image = cv2.copyMakeBorder(image, 5, 5, 5, 5, cv2.BORDER_CONSTANT,value=(14,14,14,255))            \n",
    "\n",
    "            y_range_increment = 2\n",
    "            if not champion_id.endswith(\"000\"):\n",
    "                y_range_increment = 1\n",
    "                if 'legacy_icon' in locals(): image = layer(image, legacy_icon)  \n",
    "                if 'rarity_icon' in locals(): image = layer(image, rarity_icon)  \n",
    "                    \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n",
    "\n",
    "          \n",
    "            # Create different crops to accomodate the imperfection of client screenshot percision\n",
    "            for x in range(0, 13, 2):\n",
    "                for y in range(1, 13, y_range_increment):\n",
    "                    crop = image[0+y:image.shape[1]-10+y, 0+x:image.shape[1]-10+x]              \n",
    "                    resized_image = cv2.resize(crop, (28,28), interpolation = cv2.INTER_AREA)\n",
    "                    \n",
    "                    # plt.figure()\n",
    "                    # plt.imshow(resized_image)\n",
    "                    # plt.colorbar()\n",
    "                    # plt.show()\n",
    "\n",
    "                    destination = os.path.join(\"model_training\",\"training_data\",champion_id,f'{(\"shard\",\"permanent\",\"token6\",\"token7\")[border_index]}_{\"yes\" if shadow else \"no\"}-shadow_x{x}_y{y}.png')\n",
    "                    if not os.path.exists(destination.rsplit(os.path.sep,1)[0]):\n",
    "                        os.makedirs(destination.rsplit(os.path.sep,1)[0])\n",
    "\n",
    "                    cv2.imwrite(destination, resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ward_skin_training_images( ward_image_path ):\n",
    "\n",
    "    # 1.A loading and preparing assets\n",
    "    ward = read_png(ward_image_path)\n",
    "    ward = cv2.copyMakeBorder(ward[0:ward.shape[1],:], 0, 7, 7, 0, cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "    ward_background = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"wardskin_background.png\")), (467,467))\n",
    "    shard_border = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"shard.png\")), (467,467))\n",
    "    permanent_border = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"permanent.png\")), (467,467))\n",
    "    quantity_background = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"quantity_background.png\")), (467,467))\n",
    "\n",
    "    ward_id = \"w\" + ward_image_path.rsplit(\"_\",1)[1].split(\".\")[0]\n",
    "\n",
    "    borders = (shard_border, permanent_border)\n",
    "        \n",
    "    # 2. Create variations of assets from layers\n",
    "    for border_index in range(len(borders)):\n",
    "        for shadow in (False, True):\n",
    "            image = layer(ward_background, quantity_background) if shadow else ward_background\n",
    "            image = layer(image, ward)\n",
    "            image = layer(image, borders[border_index])\n",
    "            image = cv2.copyMakeBorder(image, 5, 5, 5, 5, cv2.BORDER_CONSTANT,value=(14,14,14,255))\n",
    "                    \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n",
    "        \n",
    "            # Create different crops to accomodate the imperfection of client screenshot percision\n",
    "            for x in range(0, 13, 2):\n",
    "                for y in range(1, 13, 1):\n",
    "                    crop = image[0+y:image.shape[1]-10+y, 0+x:image.shape[1]-10+x]              \n",
    "                    resized_image = cv2.resize(crop, (28,28), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                    destination = os.path.join(\"model_training\",\"training_data\",ward_id,f'{(\"shard\",\"permanent\")[border_index]}_{\"yes\" if shadow else \"no\"}-shadow_x{x}_y{y}.png')\n",
    "                    if not os.path.exists(destination.rsplit(os.path.sep,1)[0]):\n",
    "                        os.makedirs(destination.rsplit(os.path.sep,1)[0])\n",
    "\n",
    "                    cv2.imwrite(destination, resized_image)"
   ]
  },
  {
   "source": [
    "# Generate the images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get champion and skins assets\n",
    "champions_and_skins = glob.glob(os.path.join(\"model_training\",\"assets\",\"champions_and_skins\",\"*.jpg\"))\n",
    "\n",
    "# Get ward skin assets while ignoring their shadow png image\n",
    "ward_skins = glob.glob(os.path.join(\"model_training\",\"assets\",\"ward_skins\",\"*.png\"))\n",
    "ward_skins = list(filter(lambda ward: \"shadow\" not in ward, ward_skins))\n",
    "\n",
    "# Generate training data if the lookup_table contains the ID\n",
    "# If ID is missing in lookup table run \"generate_lookup_table.py\"\n",
    "# If ID is still missing, this champion is very fresh as wikipedia doesn't know of him :)\n",
    "missing_ids = []\n",
    "\n",
    "for image in champions_and_skins:\n",
    "    champion_id = image.rsplit(os.path.sep,1)[1].split('.')[0]\n",
    "    if champion_id in lookup_table:\n",
    "        print(\"Generating training data for: \"+lookup_table[champion_id][0])\n",
    "        generate_champion_and_skin_training_images(image)\n",
    "    else:\n",
    "        missing_ids.append(champion_id)\n",
    "        print(\"Warning: Champion with ID: [\"+champion_id+\"] couldn't be found.\")\n",
    "\n",
    "for image in ward_skins:\n",
    "    ward_id = \"w\" + image.rsplit(\"_\",1)[1].split(\".\")[0]\n",
    "    if ward_id in lookup_table:\n",
    "        print(\"Generating training data for: \"+lookup_table[ward_id][0])\n",
    "        generate_ward_skin_training_images(image)\n",
    "    else:\n",
    "        missing_ids.append(ward_id)\n",
    "        print(\"Warning: Ward skin with ID: [\"+ward_id+\"] couldn't be found. Ignored.\")\n",
    "\n",
    "if len(missing_ids) > 0:\n",
    "    print(\"#################################################\")\n",
    "    print(\"Missing IDs (read comments in code for more info)\")\n",
    "    for id in missing_ids:\n",
    "        print(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image_paths = glob.glob( os.path.join(\"model_training\",\"training_data\",\"**\",\"*.png\") )\n",
    "\n",
    "train_labels = []\n",
    "train_images = []\n",
    "\n",
    "for i in range(len(train_image_paths)):\n",
    "    if i%1000 == 0:\n",
    "        print(\"Progress: \" + str(i//1000) + \"/\" + str(len(train_image_paths)//1000))\n",
    "\n",
    "    image = train_image_paths[i]\n",
    "    asset_id = image.rsplit(os.path.sep, 2)[1]\n",
    "    label = list(lookup_table.keys()).index(asset_id)\n",
    "\n",
    "    image = read_png(image)\n",
    "    image = image / 255\n",
    "\n",
    "    train_labels.append(label)\n",
    "    train_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = glob.glob(os.path.join(\"model_training\",\"testing_data\",\"28\",\"**\",\"*.png\"))\n",
    "test_labels = []\n",
    "test_images = []\n",
    "\n",
    "\n",
    "for i in range(len(test_image_paths)):\n",
    "    if i%100 == 0:\n",
    "        print( str(i//100) + os.path.sep + str(len(test_image_paths)//100))\n",
    "\n",
    "    image = test_image_paths[i]\n",
    "    asset_id = image.rsplit(os.path.sep, 2)[1]\n",
    "    label = list(lookup_table.keys()).index(asset_id)\n",
    "\n",
    "    image = read_png(image)\n",
    "    image = image[:,:,0] / 255\n",
    "\n",
    "    test_labels.append(label)\n",
    "    test_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i*12500])\n",
    "    plt.xlabel(lookup_table[list(lookup_table.keys())[train_labels[i*12500]]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(test_images[i*5])\n",
    "    plt.xlabel(lookup_table[list(lookup_table.keys())[test_labels[i*5]]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    # tf.keras.layers.Dense(len(champions)*2, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(lookup_table))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit( train_images, train_labels, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(lookup_table[list(lookup_table.keys())[predicted_label]],\n",
    "                                100*np.max(predictions_array),\n",
    "                                lookup_table[list(lookup_table.keys())[true_label]]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')\n",
    "\n",
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 32\n",
    "num_cols = 14\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "model.save                             (os.path.join(\"model_training\",\"models\",\"model_champions_skins_wards\",\"model.h5\"))\n",
    "model.save                             (os.path.join(\"model_training\",\"models\",\"model_champions_skins_wards\",\"model\"))\n",
    "model.save_weights                     (os.path.join(\"model_training\",\"models\",\"model_champions_skins_wards\",\"model_weights_checkpoint\",\"model_weights\"))\n",
    "tfjs.converters.save_keras_model(model, os.path.join(\"model_training\",\"models\",\"model_champions_skins_wards\",\"model_js\"))"
   ]
  },
  {
   "source": [
    "# Loot icon number/count recognition model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "number_train_labels = []\n",
    "number_train_images = []\n",
    "\n",
    "numbers_image = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEYAAACTAQMAAAAJE/1bAAAAAXNSR0IB2cksfwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAZQTFRFAAAA////pdmf3QAAAhFJREFUeJyNzz9r20AYx/GjGKNBlDNdBA1BQ4aMJwLtmYRGAbVT+h5cktGGZHOoWrtOiDUYTDaHhPY1ZAt0qHHFNYMSz4YMNinemlZ4afDSe05/fFLkNNvDDZ/7fRHGW8Nm/ZVGkLWLTUd5YjnIKmDk4JzJL4xQvYAUcS3VjxRLQSZu6PUjjT9gwzcPVKzrCJObUfvgI90BZSNUDNzgitVCFkHmp0Jumb8Rc6krFIs0dEcoxLjrNlVMdUT/o+gZSg8UN1SeagllUyj5lEKs/YK6DJf5Iq3QUCkFymGGouVeC8Xdf6bacJVecsVNKMW7bvuRSvu5rGhoW1KmoFQjpQaKjzdaKcUl5KeknCksUC5ipT9fWcG9pOKBst71QSmTHnlIIUJpCaUlFDZfYUllEirlCQVlExSNK/m3oXICiisUR1K0lNI/rK1VQdny1EjxYqX/NVKGM+VYKHvTYagYE58rtqwwUBbyFVCMMSjXaWWgMRooi9SOt1ChvPOUjC1ZRcdhUXJLVlFlVpS1JS6CLcWg6C8qT4VyeYrYKlcWhULjIlpaH/kdxn+jPTKYFX2mc5Sr1Y6sfAOFPazsScqNt/BmpvyKlQ+RcioURgbTWPlC7T/3lT4o53MVG5Qdrowpqr5PKE1J+X0NyvdQKUbKWFZ208oaKO17yo+0cktLtVApgtIJlFGg2LFSeYxyFSu3kvIP9ENXILgWa2YAAAAASUVORK5CYII=\"\n",
    "encoded_data = numbers_image.split(',')[1]\n",
    "nparr = np.frombuffer(base64.b64decode(encoded_data), np.uint8)\n",
    "img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)[:,:,0] / 255\n",
    "\n",
    "for x in range(0, img.shape[1], 7):\n",
    "    for y in range(0, img.shape[0], 7):\n",
    "        crop = img[y:y+7, x:x+7]\n",
    "\n",
    "        number_train_labels.append(x//7)\n",
    "        number_train_images.append(crop)\n",
    "\n",
    "model_number = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(7, 7)),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model_number.compile(optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "number_train_labels = np.array(number_train_labels)\n",
    "number_train_images = np.array(number_train_images)\n",
    "\n",
    "model_number.fit( number_train_images, number_train_labels, epochs=5000)\n",
    "\n",
    "model_number.summary()\n",
    "\n",
    "model_number.save                             (os.path.join(\"model_training\",\"models\",\"model_numbers\",\"model.h5\"))\n",
    "model_number.save                             (os.path.join(\"model_training\",\"models\",\"model_numbers\",\"model\"))\n",
    "model_number.save_weights                     (os.path.join(\"model_training\",\"models\",\"model_numbers\",\"model_weights_checkpoint\",\"model_weights\"))\n",
    "tfjs.converters.save_keras_model(model_number, os.path.join(\"model_training\",\"models\",\"model_numbers\",\"model_js\"))"
   ]
  },
  {
   "source": [
    "# Shard/Permanent model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shard_permanent_image_paths = glob.glob( os.path.join(\"model_training\",\"training_data\",\"**\",\"*.png\") )\n",
    "\n",
    "shard_permanent_train_labels = []\n",
    "shard_permanent_train_images = []\n",
    "\n",
    "for i in range(len(shard_permanent_image_paths)):\n",
    "    if i%1000 == 0:\n",
    "        print(\"Progress: \" + str(i//1000) + \"/\" + str(len(shard_permanent_image_paths)//1000))\n",
    "\n",
    "    image = shard_permanent_image_paths[i]\n",
    "    label = 0 if \"shard\" in image else 1\n",
    "\n",
    "    image = read_png(image) / 255\n",
    "\n",
    "    shard_permanent_train_labels.append(label)\n",
    "    shard_permanent_train_images.append(image)\n",
    "\n",
    "shard_permanent_train_images = np.array(shard_permanent_train_images)\n",
    "shard_permanent_train_labels = np.array(shard_permanent_train_labels)\n",
    "\n",
    "model_shard_permanent = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model_shard_permanent.compile(optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "    \n",
    "model_shard_permanent.fit( shard_permanent_train_images, shard_permanent_train_labels, epochs=10)\n",
    "\n",
    "model_shard_permanent.summary()\n",
    "\n",
    "model_shard_permanent.save                             (os.path.join(\"model_training\",\"models\",\"model_shard_permanent\",\"model.h5\"))\n",
    "model_shard_permanent.save                             (os.path.join(\"model_training\",\"models\",\"model_shard_permanent\",\"model\"))\n",
    "model_shard_permanent.save_weights                     (os.path.join(\"model_training\",\"models\",\"model_shard_permanent\",\"model_weights_checkpoint\",\"model_weights\"))\n",
    "tfjs.converters.save_keras_model(model_shard_permanent, os.path.join(\"model_training\",\"models\",\"model_shard_permanent\",\"model_js\"))"
   ]
  }
 ]
}