{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, html, re, json, glob, base64, urllib.request, cv2\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "import numpy as np\n",
    "from blend_modes import normal\n",
    "from slpp import slpp as lua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make sure working directory is project root\n",
    "if os.getcwd().rsplit('\\\\',1)[1]==\"model_training\":\n",
    "    os.chdir( os.getcwd().rsplit('\\\\',1)[0] )\n",
    "\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# Define functions used throughout the document\n",
    "def read_png(path):\n",
    "    image = cv2.imread(path,-1)\n",
    "    return cv2.cvtColor(image,cv2.COLOR_BGR2BGRA) if len(image.shape) > 2 and image.shape[2] == 3 else image\n",
    "\n",
    "def read_jpeg(path):\n",
    "    BGR = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    BGRA = cv2.cvtColor(BGR,cv2.COLOR_BGR2BGRA)\n",
    "    BGRA[:,:,3] = 255\n",
    "    return BGRA\n",
    "\n",
    "def layer( image_a, image_b, ratio=1.):\n",
    "    return normal(image_a.astype(float), image_b.astype(float), ratio).astype(np.uint8)\n",
    "\n",
    "def save_model(model, model_name):\n",
    "    model.save                             (os.path.join(\"model_training\",\"models\",model_name,\"model.h5\"))\n",
    "    model.save                             (os.path.join(\"model_training\",\"models\",model_name,\"model\"))\n",
    "    model.save_weights                     (os.path.join(\"model_training\",\"models\",model_name,\"model_weights_checkpoint\",\"model_weights\"))\n",
    "    tfjs.converters.save_keras_model(model, os.path.join(\"public\",\"models\",model_name))\n",
    "    \n",
    "def load_model(model_name):\n",
    "    return tf.keras.models.load_model(os.path.join(\"model_training\",\"models\",model_name,\"model\"));\n",
    "\n",
    "def progressbar(it, prefix=\"\", size=60, file=sys.stdout):\n",
    "    count = len(it)\n",
    "    def show(j):\n",
    "        x = int(size*j/count)\n",
    "        file.write(\"%s[%s%s] %i/%i\\r\" % (prefix, \"#\"*x, \".\"*(size-x), j, count))\n",
    "        file.flush()        \n",
    "    show(0)\n",
    "    for i, item in enumerate(it):\n",
    "        yield item\n",
    "        show(i+1)\n",
    "    file.write(\"\\n\")\n",
    "    file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Image generation has begun\n"
     ]
    }
   ],
   "source": [
    "print(\"3. Image generation has begun\")\n",
    "\n",
    "if not os.path.isfile(os.path.join(\"public\",\"lookup_data\",\"loot.json\")):\n",
    "    exit(\"Game data file from step 1 not found. Exiting.\")\n",
    "with open(os.path.join(\"public\",\"lookup_data\",\"loot.json\")) as json_file:\n",
    "    lookup_loot = json.load(json_file)\n",
    "\n",
    "def generate_champion_and_skin_training_images( champion_image_path ):\n",
    "    \n",
    "    champion_id = champion_image_path.rsplit(os.path.sep,1)[1].split('.')[0]\n",
    "    champion_data = list(filter(lambda row: row[0] == champion_id, lookup_loot[\"champions\"]+lookup_loot[\"skins\"]))[0]\n",
    "    price = champion_data[2]\n",
    "    is_legacy = champion_data[3] == 1\n",
    "    asset_folder = \"champions\" if champion_id.endswith(\"000\") else \"skins\"  \n",
    "    \n",
    "    if len(glob.glob(os.path.join(\"model_training\",\"training_data\",asset_folder,champion_id,\"*.png\"))) == 336:\n",
    "        return\n",
    "    \n",
    "    # 1.A loading and preparing assets\n",
    "    champion = cv2.copyMakeBorder(read_jpeg(champion_image_path), 0, 5, 5, 0, cv2.BORDER_CONSTANT,value=(0,0,0,255))\n",
    "    shard_border = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"shard.png\")), (385,385))\n",
    "    permanent_border = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"permanent.png\")), (385,385))\n",
    "    token_6_border = read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"champion_token_6.png\"))[5:74, :]\n",
    "    token_6_border = cv2.resize(token_6_border, (385,385))\n",
    "    token_7_border = read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"champion_token_7.png\"))[5:74, :]\n",
    "    token_7_border = cv2.resize(token_7_border, (385,385))\n",
    "    quantity_background = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"quantity_background.png\")), (385,385))\n",
    "\n",
    "    if is_legacy: legacy_icon = read_png(os.path.join(\"model_training\",\"assets\",\"tag_icons\",\"legacy.png\"))\n",
    "        \n",
    "    if price == \"special\": rarity_icon = read_png(os.path.join(\"model_training\",\"assets\",\"rarity_icons\",\"rarity_mythic.png\"))\n",
    "    if price == 3250: rarity_icon = read_png(os.path.join(\"model_training\",\"assets\",\"rarity_icons\",\"rarity_ultimate.png\"))\n",
    "    if price == 1820: rarity_icon = read_png(os.path.join(\"model_training\",\"assets\",\"rarity_icons\",\"rarity_legendary.png\"))\n",
    "    if price == 1350: rarity_icon = read_png(os.path.join(\"model_training\",\"assets\",\"rarity_icons\",\"rarity_epic.png\"))\n",
    "\n",
    "    # 1.B Resize rarity and legacy icons to 395x395 pixel resolution overlay images\n",
    "    if 'legacy_icon' in locals():\n",
    "        legacy_icon = cv2.resize(legacy_icon, (110,110))\n",
    "        legacy_icon = cv2.copyMakeBorder(legacy_icon, 291, 0, 0, 297, cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "        legacy_icon = legacy_icon[0:395,legacy_icon.shape[1]-395:legacy_icon.shape[1]]\n",
    "\n",
    "    if 'rarity_icon' in locals():\n",
    "        rarity_icon = cv2.resize(rarity_icon, (385,int(385/rarity_icon.shape[1]*rarity_icon.shape[0])))\n",
    "        rarity_icon = cv2.copyMakeBorder(rarity_icon, 285, 5, 5, 5, cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "        rarity_icon = rarity_icon[0:395,0:395]\n",
    "\n",
    "    # 2. Set up borders this asset uses in the loot tab\n",
    "    if champion_id.endswith(\"000\"):\n",
    "        borders = (shard_border, permanent_border, token_6_border, token_7_border)\n",
    "    else:\n",
    "        borders = (shard_border, permanent_border)\n",
    "    \n",
    "    # 3. Create variations of assets from layers\n",
    "    for border_index in range(len(borders)):\n",
    "        for shadow in (False, True):\n",
    "            image = layer(champion, quantity_background) if shadow else champion\n",
    "            image = layer(image, borders[border_index])\n",
    "            image = cv2.copyMakeBorder(image, 5, 5, 5, 5, cv2.BORDER_CONSTANT,value=(14,14,14,255))            \n",
    "\n",
    "            y_range_increment = 2\n",
    "            if not champion_id.endswith(\"000\"):\n",
    "                y_range_increment = 1\n",
    "                if 'legacy_icon' in locals(): image = layer(image, legacy_icon)  \n",
    "                if 'rarity_icon' in locals(): image = layer(image, rarity_icon)  \n",
    "                    \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n",
    "\n",
    "        \n",
    "            # Create different crops to accomodate the imperfection of client screenshot percision\n",
    "            for x in range(0, 13, 2):\n",
    "                for y in range(1, 13, y_range_increment):\n",
    "                    crop = image[0+y:image.shape[1]-10+y, 0+x:image.shape[1]-10+x]              \n",
    "                    resized_image = cv2.resize(crop, (28,28), interpolation = cv2.INTER_AREA)\n",
    "                                            \n",
    "                    destination = os.path.join(\"model_training\",\"training_data\",asset_folder,champion_id,f'{(\"shard\",\"permanent\",\"token6\",\"token7\")[border_index]}_{\"yes\" if shadow else \"no\"}-shadow_x{x}_y{y}.png')\n",
    "\n",
    "                    if not os.path.exists(destination.rsplit(os.path.sep,1)[0]):\n",
    "                        os.makedirs(destination.rsplit(os.path.sep,1)[0])\n",
    "\n",
    "                    cv2.imwrite(destination, resized_image)\n",
    "\n",
    "\n",
    "\n",
    "# First import libraries.\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The folliwing line is useful in Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def generate_ward_skin_training_images( ward_image_path ):\n",
    "\n",
    "    ward_id = ward_image_path.rsplit(\"_\",1)[1].split(\".\")[0]\n",
    "\n",
    "    if len(glob.glob(os.path.join(\"model_training\",\"training_data\",\"wards\",ward_id,\"*.png\"))) == 336:\n",
    "        return\n",
    "\n",
    "    # 1.A loading and preparing assets\n",
    "    ward = read_png(ward_image_path)\n",
    "    ward_shape = np.shape(ward)\n",
    "    \n",
    "    # If shape doesn't match, we're crop resizing to fit the rest of the wards\n",
    "    if ( ward_shape[0] > 550 or ward_shape[1] > 460):\n",
    "        if ( ward_shape[1]/ward_shape[0] > 460/550):\n",
    "            # image ratio is wider than targer\n",
    "            ward = cv2.resize(ward, (int(550/ward_shape[0]*ward_shape[1]) ,550))\n",
    "            padding = (np.shape(ward)[1]-460)//2\n",
    "            ward = ward[0:550,padding:460+padding]\n",
    "        else:\n",
    "            # image ratio is taller than target (untested - there was no use case for this)\n",
    "            ward = cv2.resize(ward, (460, int(460/ward_shape[1]*ward_shape[0])))\n",
    "            padding = (np.shape(ward)[0]-550)//2\n",
    "            ward = ward[padding:550+padding,0:460]\n",
    "        plt.imshow(Image.fromarray(np.uint8(ward)))\n",
    "            \n",
    "    ward = cv2.copyMakeBorder(ward[0:ward.shape[1],:], 0, 7, 7, 0, cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "    ward_background = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"wardskin_background.png\")), (467,467))\n",
    "    shard_border = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"shard.png\")), (467,467))\n",
    "    permanent_border = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"permanent.png\")), (467,467))\n",
    "    quantity_background = cv2.resize(read_png(os.path.join(\"model_training\",\"assets\",\"border_images\",\"quantity_background.png\")), (467,467))\n",
    "\n",
    "\n",
    "    borders = (shard_border, permanent_border)\n",
    "        \n",
    "    # 2. Create variations of assets from layers\n",
    "    for border_index in range(len(borders)):\n",
    "        for shadow in (False, True):\n",
    "            image = layer(ward_background, quantity_background) if shadow else ward_background\n",
    "            image = layer(image, ward)\n",
    "            image = layer(image, borders[border_index])\n",
    "            image = cv2.copyMakeBorder(image, 5, 5, 5, 5, cv2.BORDER_CONSTANT,value=(14,14,14,255))\n",
    "                    \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n",
    "        \n",
    "            # Create different crops to accomodate the imperfection of client screenshot percision\n",
    "            for x in range(0, 13, 2):\n",
    "                for y in range(1, 13, 1):\n",
    "                    crop = image[0+y:image.shape[1]-10+y, 0+x:image.shape[1]-10+x]              \n",
    "                    resized_image = cv2.resize(crop, (28,28), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                    destination = os.path.join(\"model_training\",\"training_data\",\"wards\",ward_id,f'{(\"shard\",\"permanent\")[border_index]}_{\"yes\" if shadow else \"no\"}-shadow_x{x}_y{y}.png')\n",
    "\n",
    "                    if not os.path.exists(destination.rsplit(os.path.sep,1)[0]):\n",
    "                        os.makedirs(destination.rsplit(os.path.sep,1)[0])\n",
    "\n",
    "                    cv2.imwrite(destination, resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  Generating champion/skin images: [########################################] 1464/1464\n",
      "-  Generating ward skin images: [########################################] 220/220\n",
      "!   Missing asset data. Perhaps a new ward has been released?\n",
      "!   The model will not be able to classify this asset.\n",
      "!   IDs with missing data: 221\n",
      "-  Generating collection champion images: [########################################] 157/157\n",
      "-  Generating collection skin images: [########################################] 1651/1651\n",
      "-  Image generation complete\n"
     ]
    }
   ],
   "source": [
    "# Get champion and skins assets\n",
    "champions_and_skins = glob.glob(os.path.join(\"model_training\",\"assets\",\"champions_and_skins\",\"*.jpg\"))\n",
    "\n",
    "# Generate training data if the lookup_loot contains the ID\n",
    "# If ID is missing in lookup table run \"generate_lookup_loot.py\"\n",
    "# If ID is still missing, this champion is very fresh as wikipedia doesn't know of him :)\n",
    "missing_ids = []\n",
    "\n",
    "for i in progressbar(range(len(champions_and_skins)), \"-  Generating champion/skin images: \", 40):\n",
    "    image = champions_and_skins[i]\n",
    "    champion_id = image.rsplit(os.path.sep,1)[1].split('.')[0]\n",
    "    champion_data = list(filter(lambda row: row[0] == champion_id, lookup_loot[\"champions\"]+lookup_loot[\"skins\"]))\n",
    "    if len(champion_data) > 0:\n",
    "        generate_champion_and_skin_training_images(image)\n",
    "    else:\n",
    "        missing_ids.append(champion_id)\n",
    "\n",
    "if len(missing_ids) > 0:\n",
    "    print(\"!   Missing asset data. Perhaps a new champion/skin has been released?\")\n",
    "    print(\"!   The model will not be able to classify this \")\n",
    "    print(\"!   IDs with missing data: \"+\",\".join(map(lambda x: str(x), missing_ids)))\n",
    "    if input(\"Would you like to continue? (y/n)\").lower() == \"n\":\n",
    "        exit()\n",
    "\n",
    "# Get ward skin assets while ignoring their shadow png image\n",
    "ward_skins = glob.glob(os.path.join(\"model_training\",\"assets\",\"ward_skins\",\"*.png\"))\n",
    "ward_skins = list(filter(lambda ward: \"shadow\" not in ward, ward_skins))\n",
    "\n",
    "# Generate training data if the lookup_loot contains the ID\n",
    "# If ID is missing in lookup table run action 1 again.\n",
    "# If ID is still missing, this champion is very fresh as wikipedia doesn't know of him :)\n",
    "missing_ids = []\n",
    "\n",
    "for i in progressbar(range(len(ward_skins)), \"-  Generating ward skin images: \", 40):\n",
    "    image = ward_skins[i]\n",
    "    ward_id = image.rsplit(\"_\",1)[1].split(\".\")[0]\n",
    "    ward_data = list(filter(lambda row: row[0] == int(ward_id), lookup_loot[\"wards\"]))\n",
    "    if len(ward_data) > 0:\n",
    "        generate_ward_skin_training_images(image)\n",
    "    else:\n",
    "        missing_ids.append(ward_id)\n",
    "\n",
    "if len(missing_ids) > 0:\n",
    "    print(\"!   Missing asset data. Perhaps a new ward has been released?\")\n",
    "    print(\"!   The model will not be able to classify this asset.\")\n",
    "    print(\"!   IDs with missing data: \"+\",\".join(map(lambda x: str(x), missing_ids)))\n",
    "    if input(\"Would you like to continue? (y/n)\").lower() == \"n\":\n",
    "        exit()\n",
    "\n",
    "def generate_collection_champion_training_images( champion_image_path ):\n",
    "        \n",
    "    champion_id = champion_image_path.rsplit(os.path.sep,1)[1].split('.')[0]\n",
    "    \n",
    "    if len(glob.glob(os.path.join(\"model_training\",\"training_data\",\"collection_champions\",champion_id,\"*.png\"))) == 49:\n",
    "        return\n",
    "    \n",
    "    image = read_png(champion_image_path)[0:377,:]\n",
    "\n",
    "    bg = np.zeros((image.shape[0], image.shape[1], image.shape[2]), np.uint8)\n",
    "    bg[:] = (22, 13, 1, 255)\n",
    "\n",
    "    image = layer(bg, image, 0.8)    \n",
    "    image = cv2.copyMakeBorder(image, 5, 5, 5, 5, cv2.BORDER_CONSTANT,value=(30,35,40,255))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n",
    "\n",
    "    for x in range(0, 13, 2):\n",
    "        for y in range(0, 13, 2):\n",
    "            crop = image[0+y:image.shape[0]-10+y, 0+x:image.shape[1]-10+x]              \n",
    "            resized_image = cv2.resize(crop, (28,28), interpolation = cv2.INTER_AREA)\n",
    "                    \n",
    "            destination = os.path.join(\"model_training\",\"training_data\",\"collection_champions\",champion_id,f'x{x}_y{y}.png')\n",
    "\n",
    "            if not os.path.exists(destination.rsplit(os.path.sep,1)[0]):\n",
    "                os.makedirs(destination.rsplit(os.path.sep,1)[0])\n",
    "\n",
    "            cv2.imwrite(destination, resized_image)\n",
    "\n",
    "coll_champion = glob.glob(os.path.join(\"model_training\",\"assets\",\"loading_screen_assets\",\"*.png\"))\n",
    "coll_champion = list(filter(lambda path: path.endswith(\"000.png\"), coll_champion))\n",
    "\n",
    "\n",
    "for i in progressbar(range(len(coll_champion)), \"-  Generating collection champion images: \", 40):\n",
    "    path = coll_champion[i]\n",
    "    generate_collection_champion_training_images(path)\n",
    "\n",
    "\n",
    "\n",
    "def generate_collection_skin_training_images( skin_image_path ):    \n",
    "    skin_id = skin_image_path.rsplit(os.path.sep,1)[1].split('.')[0]\n",
    "\n",
    "    if len(glob.glob(os.path.join(\"model_training\",\"training_data\",\"collection_skins\",skin_id,\"*.png\"))) == 49:\n",
    "        return\n",
    "    \n",
    "    image = read_png(skin_image_path)[18:409,14:291]\n",
    "\n",
    "    bg = np.zeros((image.shape[0], image.shape[1], image.shape[2]), np.uint8)\n",
    "    bg[:] = (22, 13, 1, 255)\n",
    "\n",
    "    image = layer(bg, image, 0.8)    \n",
    "    image = cv2.copyMakeBorder(image, 5, 5, 5, 5, cv2.BORDER_CONSTANT,value=(30,35,40,255))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n",
    "\n",
    "    for x in range(0, 13, 2):\n",
    "        for y in range(0, 13, 2):\n",
    "            crop = image[0+y:image.shape[0]-10+y, 0+x:image.shape[1]-10+x]              \n",
    "            resized_image = cv2.resize(crop, (28,28), interpolation = cv2.INTER_AREA)\n",
    "                    \n",
    "            destination = os.path.join(\"model_training\",\"training_data\",\"collection_skins\",skin_id,f'x{x}_y{y}.png')\n",
    "\n",
    "            if not os.path.exists(destination.rsplit(os.path.sep,1)[0]):\n",
    "                os.makedirs(destination.rsplit(os.path.sep,1)[0])\n",
    "\n",
    "            cv2.imwrite(destination, resized_image)\n",
    "\n",
    "\n",
    "coll_skin = glob.glob(os.path.join(\"model_training\",\"assets\",\"loading_screen_assets\",\"*.png\"))\n",
    "coll_skin = list(filter(lambda path: not path.endswith(\"000.png\"), coll_skin))\n",
    "    \n",
    "for i in progressbar(range(len(coll_skin)), \"-  Generating collection skin images: \", 40):\n",
    "    path = coll_skin[i]\n",
    "    generate_collection_skin_training_images(path)\n",
    "\n",
    "\n",
    "print(\"-  Image generation complete\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23a6b913c5c0dcb48130fb95bc8c7b084c5a812df45cbb14e417b737a9d4ee46"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
